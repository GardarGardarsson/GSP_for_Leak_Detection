{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea40f6e",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Table of Contents:\n",
    "1. [Make Graph](#makegraph)\n",
    "2. [Read in Yearly Prediction and Scale Back to Original Interval](#readscale)\n",
    "3. [Exploratory Data Analysis](#eda) <br>\n",
    "    3.1 [Data Wrangling](#wrangling) <br>\n",
    "    3.2 [Calculating Per-Node Error](#node-error) <br>\n",
    "    3.3 [Calculating Per-Pipe Error](#pipe-error) <br>\n",
    "    3.4 [Leakage Labelset](#leaks) <br>\n",
    "    3.5 [Dataset Pre-Processing](#pre-process) <br>\n",
    "5. [Boem et al. Residual Analysis](#residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fb90b",
   "metadata": {},
   "source": [
    "# Leak Detection\n",
    "\n",
    "> Garðar Örn Garðarsson <br>\n",
    "Integrated Machine Learning Systems 20-21 <br>\n",
    "University College London"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d754a",
   "metadata": {},
   "source": [
    "<a id='makegraph'></a>\n",
    "*Back to [Table of Contents](#toc)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c9c5b",
   "metadata": {},
   "source": [
    "## 1. Make Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b838c",
   "metadata": {},
   "source": [
    "Convert the `EPANET` model to a `networkx` graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e944d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import epynet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.epanet_loader import get_nx_graph\n",
    "from utils.epanet_simulator import epanetSimulator\n",
    "from utils.data_loader import battledimLoader, dataCleaner, dataGenerator, embedSignalOnGraph, rescaleSignal\n",
    "from modules.torch_gnn import ChebNet\n",
    "from utils.visualisation import visualise\n",
    "\n",
    "# Runtime configuration\n",
    "path_to_wdn     = './data/L-TOWN.inp'\n",
    "path_to_data    = './data/l-town-data/'\n",
    "weight_mode     = 'pipe_length'\n",
    "self_loops      = True\n",
    "scaling         = 'minmax'\n",
    "figsize         = (50,16)\n",
    "print_out_rate  = 1               \n",
    "model_name      = 'l-town-chebnet-' + weight_mode +'-' + scaling + '{}'.format('-self_loop' if self_loops else '')\n",
    "last_model_path = './studies/models/' + model_name + '-1.pt'\n",
    "last_log_path   = './studies/logs/'   + model_name + '-1.csv' \n",
    "\n",
    "# Import the .inp file using the EPYNET library\n",
    "wdn = epynet.Network(path_to_wdn)\n",
    "\n",
    "# Solve hydraulic model for a single timestep\n",
    "wdn.solve()\n",
    "\n",
    "# Convert the file using a custom function, based on:\n",
    "# https://github.com/BME-SmartLab/GraphConvWat \n",
    "G , pos , head = get_nx_graph(wdn, weight_mode=weight_mode, get_head=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82305013",
   "metadata": {},
   "source": [
    "<a id='readscale'></a>\n",
    "*Back to [Table of Contents](#toc)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd48d98",
   "metadata": {},
   "source": [
    "## 2. Read in Yearly Prediction and Scale Back to Original Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04353b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prediction(filename='predictions.csv', scale=1, bias=0, start_date='2018-01-01 00:00:00'):\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0')\n",
    "    df.columns = ['n{}'.format(int(node)+1) for node in df.columns]\n",
    "    df = df*scale+bias\n",
    "    df.index = pd.date_range(start=start_date,\n",
    "                             periods=len(df),\n",
    "                             freq = '5min')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e23bd",
   "metadata": {},
   "source": [
    "## 2019 Detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef14e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_19 = pd.read_csv('InceptionTime_Predictions.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a552fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_19[faults_19 > 0.2] = 1      # Every label with predicted probability > 20% is classified as a leak\n",
    "faults_19[faults_19 < 1  ] = 0      # Every label that is not set to 1 is is now set to 0\n",
    "faults_19 = faults_19.astype('int') # Conversion to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c26dcb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_19 = faults_19.diff(periods=1).fillna((faults_19.iloc[0]).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4b85279",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_19 = {}\n",
    "\n",
    "for pipe in faults_19:\n",
    "    timestamp = faults_19[pipe].index[faults_19[pipe]>0]\n",
    "    if timestamp.empty:\n",
    "        continue\n",
    "    else: \n",
    "        detections_19[pipe] = timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9b5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inceptionTime_results.txt', 'w') as f:\n",
    "    f.write('#linkID, startTime\\n')\n",
    "    for key in detections_19.keys():\n",
    "        for val in detections_19[key]: \n",
    "            f.write(key + ', ' + str(val)[:-3] + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd60ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for key in detections_19.keys():\n",
    "    for val in detections_19[key]:\n",
    "        entry =[]\n",
    "        entry.append(str(val)[:-3])\n",
    "        entry.append(key)\n",
    "        results.append(entry)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.set_index(0,drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db3749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "340dd7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections_19.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534e4c6",
   "metadata": {},
   "source": [
    "124 for $\\alpha=2$\n",
    "\n",
    "691 for $\\alpha=1.5$\n",
    "\n",
    "783 for $\\alpha=1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6a5cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02aa6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = pd.read_csv('results_data.csv', index_col = '0').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514c1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections.index = pd.to_datetime(detections.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28141e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections['leakTimeStamp'] = detections.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a9f776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detections.resample('d').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c68f4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detections.replace(to_replace='None', value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8127e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections.set_index('leakTimeStamp', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1da9bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_data.txt', 'w') as f:\n",
    "    f.write('#linkID, startTime\\n')\n",
    "    for time, pipe in detections['1'].to_dict().items():\n",
    "        f.write(pipe + ', ' + str(time)[:-3] + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4947d1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43eee061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1091e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gibberish_detections = np.random.randint(1,905,365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ce4f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateRange = pd.date_range(\"2019-01-01 00:00\", periods = 365, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e510f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_results.txt', 'w') as f:\n",
    "    f.write('#linkID, startTime\\n')\n",
    "    for pipe, time in zip(gibberish_detections, dateRange):\n",
    "        f.write('p'+ str(pipe) + ', ' + str(time)[:-3] + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab2d90",
   "metadata": {},
   "source": [
    "`(220, 1)` for $\\alpha = 1.5$\n",
    "\n",
    "`(317, 1)` for $\\alpha = 1.0$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
